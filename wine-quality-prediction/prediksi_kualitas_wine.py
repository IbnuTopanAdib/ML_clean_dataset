# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zUDbridEeKKi9zepsNlMWjcVt2DUn35E

# Predictive Analysis, Prediksi Kualitas White Wine

## Import Library Yang DIbutuhkan
"""

import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns
import time

"""## Data Understanding

### Data Loading
"""

df = pd.read_csv('data/winequality-white.csv', delimiter = ';')

"""Untu mengethaui gambaran umum dataset dengan method head() dan memberikan argumen 10 untuk menampilkan 10 record pertama dalam dataset."""

df.head(25)

"""### Exploratory Data Analysis(EDA)

Exploratory data analysis atau sering disingkat EDA merupakan proses investigasi awal pada data untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data. Teknik ini biasanya menggunakan bantuan statistik dan representasi grafis atau visualisasi.

#### Deskripsi Variabel

Untuk mengetahui mengenai informasi tentang dataset seperti jumlah kolom, nama kolom, jumlah baris dan tipe data dari setiap kolom digunakan method info() dari library pandas.
"""

df.info()

"""Dari hasil output tersebut didapatkan beberapa informasi diantaranya:
- jumlah record pada dataset adalah 4989
- Jumlah fitur yang ada pada dataset adalah 10 dengan fitur `quality` sebagai fitur target atau label
- Semua fitur merupakan fitur numerik dengan tipe data float64 sedangkan fitur target bertipe data int64

Selanjutnya dilakukan pemeriksaan terhadap parameter statistik seperti nilai rata-rata, median, persentil 25, persentil 75 dll. untuk mengetahui pemustan dan persebaran data pada dataset
"""

df.describe()

"""#### Menangani Missing Value

Untuk mengetahui apakah ada missing value dalam dataset,digunakan metode isna() dan di chaining dengan any()
"""

df.isna().any()

"""Output diatas menunjukan tidak terdapat missing value pada dataset oleh karena itu tidak perlu dilakukan pembersihan missing value pada dataset tersebut.

#### Menghapus Nilai Duplikat

Untuk menghapus nilai duplikat kita buat fungsi yang akan menampilkan nilai True jika ada nilau duplikat dan akan menampilkan jumlah nilai duplikat yang ada kemudian menghapusnya
"""

def hapus_duplikat(df):
  ada_duplikat = df.duplicated().any()
  print(f"Apkah ada nilai duplikat : {ada_duplikat }")
  if ada_duplikat:
    print(f"jumlah nilai duplikat {df.duplicated().sum()}")
    df = df.drop_duplicates()
  print(f"jumlah nilai duplikat {df.duplicated().sum()}")
  return df

"""kemudian kita panggil fungsinya dan masukan dataset sebagai parameter"""

df.duplicated().sum()

df = hapus_duplikat(df)

"""#### Menangani Outliers

Untuk mengetahui apakah ada outlier pada dataset kita akan menggunakan teknik visualisasi dengan boxplot
"""

plt.figure(figsize = (10, 10))

df_boxplot = df[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',
       'pH', 'sulphates', 'alcohol']]

sns.boxplot(data=df_boxplot, palette="rocket")
plt.yscale('log')
plt.xticks(rotation = 45)
plt.savefig('/boxplot1.png')
plt.show()

"""berdasarkan visualisasi diatas ditemukan beberapa outlier pada dataset untuk menangani outlier tersebut kita bisa menggunakan IQR method."""

stats = df.describe().transpose()

Q1 = stats['25%']
Q3 = stats['75%']
IQR = Q3 - Q1
BATAS_BAWAH = Q1 - 1.5 * IQR

BATAS_ATAS = Q3 + 1.5 * IQR
df = df.loc[~((df < BATAS_BAWAH) | (df> BATAS_ATAS)).any(axis =1)]

"""IQR sangat berguna dalam menemukan outlier, yang merupakan nilai yang secara signifikan berbeda dari data lainnya. Kita dapat menggunakan IQR untuk mengidentifikasi outlier dengan mempertimbangkan nilai yang berada di bawah kuartil pertama (Q1) atau di atas kuartit ketiga (Q3). Nilai apa pun di luar batas-batas ini dianggap sebagai outlier. berikut adalah visualisasi boxplot setelah dilakukan pembersihan outlier"""

plt.figure(figsize = (10, 10))

df_boxplot = df[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',
       'pH', 'sulphates', 'alcohol']]

sns.boxplot(data=df_boxplot, palette="rocket")
plt.yscale('log')
plt.xticks(rotation = 45)
plt.savefig('/boxplot2.png')
plt.show()

df.shape

"""#### Univariate analysis
Analisis univariate adalah cara kita melakukan analisis terhadap satu jenis (variasi) variabel saja. Dengan kata lain, analisis univariate merupakan proses untuk mengeksplorasi dan menjelaskan setiap variabel dalam kumpulan data secara terpisah.

Untuk menganalisis setiap fitur dalam dataset wine kita akan melihat histogram masing-masing fiturnya.
"""

df.hist(bins=50, figsize=(20,15))
plt.savefig('/histogram.png')
plt.show()

"""Berdasarkan Histogram tersebut dapat disimpulkan banyak informasi diantaranya:
1. distribusi data tingkat kekuatan asam yang tidak volatile(fixed acidity) bersifat normal (bell curved ) dimana nilai median dan rata-ratanya hampir sama. sehingga dapat disimpulkan jika rata-rata white-wine memiliki tingkat kekuatan asam sekitar nilai median yang diperkirakan sekitar 6.8.

2. distribusi data tingkat kekuatan asam volatile(volatile acidity) bersifat normal (bell curved ) dimana nilai median dan rata-ratanya hampir sama. sehingga dapat disimpulkan jika rata-rata white-wine memiliki tingkat kekuatan asam sekitar nilai median yang diperkirakan sekitar 0.26.

3. Distribusi data tingkat asam sitrat juga bersifat normal (bell curved ) dimana nilai median dan rata-ratanya hampir sama. sehingga dapat disimpulkan jika rata-rata white-wine memiliki kadar asam sitrat sekitar nilai mediannya yang diperkirakan sekitar 0.31. namun terdapat peak yang akan mempengaruhi nilai rata ratanya. tapi peak tersebut hanya satu sehingga nilai rata-rata pun tidak terlalu berpengaruh.

4. Tingkat residual sugar atau gula tersisa dalam white-wine kebanyakan rendah hal ini dikarenakan frekuensi dari white-wine yang memiliki residual sugar rendah sangat tinggi sehingga bisa disimpulkan kebanyakan white-wine tidak begitu manis.

5. tingkat konsentrasi cloride atauu klorida dalam white-wine kebanyakan berada disekitar 0.03 sampai 0.05.

6. Distribusi data Jumlah sulfur dioksida bebas dalam white-wine tidak terdistribusi secara seragam hal ini dibuktikan dengan banyaknya peak dalam histogram.

7. Distribusi data total sulfur dioksida dalam white-wine juga bersifat normal (bell curved ) dimana nilai median dan rata-ratanya hampir sama. sehingga dapat disimpulkan jika rata-rata total sulfur dioksida dalam white-wine sekitar nilai mediannya yang diperkirakan sekitar 125.

8. Density atau massa jenis dari white-wine berada antara 0.998 dan 1.

9. pH dari white-wine kebanyakan berada sekitar 3.0 - 3.4.

10. kebanyakan white wine memiliki kadar senyawa sulfat sekitar 0.49 - 50.

11. Kebanyakan dari white-wine memiliki tingkat alkohol sekitar 9.5 dan sangat sedikit sekali white-wine yang memiliki tingkat alkohol dibawah 9 dan diatas 13.

12. Tingkat kualitas dari white-wine sebenarnya berada antara 4-9 namun dikarenakan white-wine yang memliki kualitas 8 dan 9 sangatlah sedikit maka tingkat kualitas tersebut dianggap outlier. sehingga kualitas white-wine pada data hanya dari 4 - 7
dimana kebanyakn white-wine memiliki kualitas 6.

#### Multivariate Analysis

Multivariate EDA menunjukkan hubungan antara dua atau lebih variabel pada data. Untuk mengamati hubungan antara fitur dalam dataset, kita akan menggunakan fungsi pairplot().
"""

sns.pairplot(df, diag_kind = 'kde')
plt.savefig('/pairplot.png')

"""hasil visualisasi tersebut menunjukan jika tidak ada fitur yang berkorelasi tinggi dengan fitur target yaitu `quality` atau kualitas white-wine.

Untuk lebih mendalam memahami korelasi antar fitur digunakan Parameter correlation. Parameter ini digunakan untuk mengidentifikasi korelasi atau hubungan dari dua feature numerik dalam sebuah data. Korelasi ini digambarkan menggunakan nilai dengan rentang -1 hingga 1.
"""

plt.figure(figsize=(12, 12))
correlation_matrix = df.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='autumn_r', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)
plt.xticks(fontsize =16)
plt.yticks(fontsize =16)
plt.tight_layout()
plt.savefig('correlation.png')

"""Banyak fitur yang kurang berkorelasi dengan fitur target sehingga kita bisa menghapus fitur-fitur tersebut namun fitur yang dihapus hanya fitur yang korelasinya kurang dari 0.1 atau -0.1 hal ini dikarenakan jika kita menghapus banyak fitur tentunya kita akan kehilangan informasi yang mungkin berguna dari fitur tersebut. fitur tersebut diantaranya adalah fixed acidity, citric acid, sulphates, free sulfur dioxide, total sulfur dioxide."""

columns= [ 'fixed acidity', 'citric acid', 'sulphates', 'free sulfur dioxide', 'total sulfur dioxide']

df.drop(columns, inplace=True, axis=1)
df.head()

"""sehingga fitur yang tersedia adalah volatile acidity, residual sugar, chlorides	density, pH, dan alcohol.

## Data Preparation
Pada tahap ini kita akan membuat data menjadi lebih mudah untuk diproses oleh model Machine Learning. Pada tahap ini kita akan melakukan 3 hal yaitu menangani data yang tidak seimbang dengan undersampling, membagi data menjadi data training dan data test. selanjutnya kita akan melakukan feature scaling menggunakan standard scaler.

### Undersampling
"""

df.quality.value_counts().plot(kind = 'bar')
plt.title('Jumlah Kelas Target Sebelum Undersampling')

kelas_mayoritas = df[df['quality'] == 6]

jumlah_kelas_mayoritas = len(kelas_mayoritas)

jumlah_data_dihapus = int(0.2 * jumlah_kelas_mayoritas)

df = df.drop(kelas_mayoritas.sample(jumlah_data_dihapus).index)

df.quality.value_counts().plot(kind = 'bar')
plt.title('Jumlah Kelas Target Setelah Undersampling')

"""#### Train Test Split
Sebelum dilakukan feature scaling seperti normalisasi ataupun standarisasi terlebih dahulu kita bagi terlebih dahulu dataset menjadi 2 bagian yaitu data train dan data test. proporsi yang digunakan dalam pembagian ini adalah  80:20 yang artinya 80% dari data akan dijadikan training set atau data yang digunakan untuk melatih model, dan 20 % dari data akan dijadikan test set atau data yang digunakan untuk menguji model.
"""

from sklearn.model_selection import train_test_split

X = df.drop(["quality"],axis =1)
y = df["quality"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123, shuffle = False)

"""### Standarisasi
Fefeature scaling yang digunakan adalah standard scaler. StandardScaler melakukan proses standarisasi fitur dengan mengurangkan mean (nilai rata-rata) kemudian membaginya dengan standar deviasi untuk menggeser distribusi.  StandardScaler menghasilkan distribusi dengan standar deviasi sama dengan 1 dan mean sama dengan 0. Sekitar 68% dari nilai akan berada di antara -1 dan 1.
"""

df.head()

from sklearn.preprocessing import StandardScaler

numerical_features = ['volatile acidity', 'residual sugar', 'chlorides', 'density', 'pH',
       'alcohol']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""#### Modeling

Seperti yang dijelaskan pada tahap Business Understanding kita akan mengembangkan model machine learning dengan tiga algoritma yang berbeda. Kemudian, kita akan membandingkan mean absolute error dan waktu training masing-masing algoritma dan menentukan algoritma mana yang memberikan hasil prediksi terbaik. Ketiga algoritma tersebut antara lain:

1. K-Nearest Neighbor (KNN)
2. Support Vector Regression (SVR)
3. Boosting Algorithm

Pertama kita membuat dataframe untuk menyimpan waktu training yang dibutuhkan untuk masing-masing model
"""

waktu = pd.DataFrame(
  index = ['time'],
  columns = ['KNN', 'SVR', 'Boosting']
)

"""### K-Nearest Neighbor

Pertama kita akan membuat model machine learning dengan menggunakan algoritma KNN. Kita menggunakan paremeter k = 10 tetangga dan metric default atau bawaan dari sklearn yaitu Euclidean selanjutnya kita melatih model tersebut dengan data train yang sudah kita siapkan sebelumnya.
"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error

knn = KNeighborsRegressor(n_neighbors=10)
rec = time.time()
knn.fit(X_train, y_train)
waktu['KNN'] = time.time() - rec

"""kemuadian waktu dari training model akan disimpan dalam dataframe yang sudah dibuat sebelumnya yang nantinya akan digunakan untuk membandingkan algoritma mana yang paling cepat.

### SVR

Kedua kita akan membuat model machine learning dengan menggunakan algoritma SVR

parameter yang digunakan antara lain adalah sebagai berikut:
- Kernel, Kernel adalah fungsi yang digunakan untuk mengukur seberapa mirip dua titik data dalam ruang fitur yang lebih tinggi: kernel yang digunakam adalah kernel rbf
- Parameter C Parameter C mengendalikan trade-off antara error pelatihan dan kompleksitas model: parameter c yang digunakan adalah 100
- Parameter gamma Parameter gamma mengontrol seberapa banyak pengaruh satu titik data tunggal: parameter gamma yang digunakan adalah 0.1
"""

from sklearn.svm import SVR


svr = SVR(kernel="rbf", C=100, gamma=0.1)
rec = time.time()
svr.fit(X_train, y_train)
waktu['SVR'] = time.time() - rec

"""Selanjutnya kita akan menyimpan waktu training dari model untuk kemudian dilakukan evaluasi terhadap model pada tahap evaluasi.

### Boosting Algorithm
"""

from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=123)
rec = time.time()
boosting.fit(X_train, y_train)
waktu['Boosting'] = time.time() - rec

"""## Evaluation

Sebelum dilakukan pengujian dengan data test kita standarisasi terlebih dahulu data test tersebut.
"""

X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""#### Mean Absolute Error (MAE)
Mean Absolute Error (MAE) adalah salah satu metrik evaluasi untuk mengukur seberapa dekat prediksi model regresi yang kita buat(y predict) terhadap nilai sebenarnya (y). MAE mengukur rata-rata selisih absolut antara nilai prediksi dan nilai sebenarnya. Selanjutnya kita akan mengevaluasi ketiga model dengan menggunakan MAE.

Selanjutnya, evaluasi ketiga model kita dengan MAE
"""

mae = pd.DataFrame(columns=['train', 'test'], index=['KNN','SVM','Boosting'])


model_dict = {'KNN': knn, 'SVM': svr, 'Boosting': boosting}

for name, model in model_dict.items():
    mae.loc[name, 'train'] = mean_absolute_error(y_true=y_train, y_pred=model.predict(X_train))
    mae.loc[name, 'test'] = mean_absolute_error(y_true=y_test, y_pred=model.predict(X_test))

mae

"""Agar lebih mudah dipahami kita visualisasikan dataframe tersebut"""

fig, ax = plt.subplots(figsize = (8,8))
mae.plot(kind='bar', ax=ax, zorder=3)
ax.grid(zorder=0)
plt.savefig('/mae.png')

"""Berdasarkan nilai-nilai MAE di atas, kita dapat menyimpulkan beberapa hal:

- Model SVM memiliki performa yang lebih baik daripada model KNN dan Boosting pada data training Ini ditunjukkan oleh fakta bahwa nilai MAE untuk SVM lebih rendah daripada nilai MAE untuk model lainnya. namun model ini mengalami *overfitting* yang ditandai dengan error yang lebih tinggi pada data test

- Model Boosting memiliki MAE yang lebih rendah pada data testing dari kedua model, namun model ini memiliki  MAE yang lebih tinggi pada data training dibandingkan kedua model.

- Model KNN
Model KNN memiliki MAE kedua terendah setelah model SVM pada data training dan model ini juga memiliki selisih yang tipis dengan model yang memiliki MAE terendah yaitu boosting

Kita ingin memilih model yang memiliki kestabilan antara performa pada data training dan testing, oleh karena itu model KNN menjadi pilihan yang sesuai. Meskipun model Boosting memiliki nilai MAE terendah pada data testing, tetapi memiliki perbedaan yang signifikan antara performa pada data training dan testing, menunjukkan adanya underfitting. Di sisi lain, model KNN memiliki performa yang baik pada kedua data, training dan testing, dengan selisih yang lebih sedikit antara nilai-nilai MAE, menunjukkan kestabilan yang lebih baik dalam generalisasi ke data yang tidak dilihat sebelumnya.

### Prediksi
Berikut adalah prediksi ketiga model terhadap sepuluh sample pertama dari dataset.
"""

prediksi = X_test.iloc[:10].copy()
pred_dict = {'y_true':y_test[:10]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi)

pd.DataFrame(pred_dict)

"""### Waktu Training Model

Sebelumnya kita telah menyimpan waktu eksekusi di dataframe `waktu` selnjutnya kita tampilkan waktu training untuk masing - masing model
"""

waktu

"""Agar lebih mudah dipahami kita visualisasikan data tersebut"""

waktu_transposed = waktu.T

plt.figure(figsize=(10, 6))
ax = waktu_transposed.plot(kind='bar', legend=False)


for i, v in enumerate(waktu_transposed.values):
    ax.text(i, v + 0.05, format(v[0], '.5f'), ha='center', va='bottom', fontweight='bold')

plt.title('Waktu Training Model')
plt.xlabel('Model')
plt.ylabel('Waktu Training (detik)')

plt.savefig('/timex.png')
plt.show()

"""Model KNN memiliki waktu training yang sangat singkat dibandingkan dengan kedua model lainnya. Model Boosting memiliki waktu training kedua lebih cepat dibandingkan SVM sedangkan model SVM memiliki waktu yang jauh lebih lama dibandingkan 2 model lainnya.

## Kesimpulan

- Tidak ada fitur yang berkorelasi tinggi dengan kelas target yaitu quality atau kualitas wine. namun terdapat fitur yang cukup berkorelasi dengan kualitas white-wine diantaranya adalah fitur
volatile acidity, residual sugar, chlorides	density, pH, dan alcohol.

- Setelah membandingkan akurasi dan juga waktu training model dapat disimpulkan jika model terbaik untuk memprediksi kualitas *white-wine* adalah model KNN. model KNN tidak hanya menawarkan kestabilan antara performa pada data training dan testing, tetapi juga menjadi pilihan yang cepat dalam hal eksekusi. Ini menjadikannya solusi yang baik jika kita ingin mendapatkan hasil yang baik dengan waktu eksekusi yang relatif lebih singkat.
"""